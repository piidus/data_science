{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d18a1c3-7d5e-4fa7-9297-3ce8cca2e31d",
   "metadata": {},
   "source": [
    "### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4522a-0edb-4ae4-a35d-ffa0b4f28bbc",
   "metadata": {},
   "source": [
    ">Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. Web scraping software may directly access the World Wide Web using the Hypertext Transfer Protocol or a web browser. \n",
    "\n",
    ">While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis.\n",
    "\n",
    ">Three areas ::\n",
    ">>1. Lead Generation for Marketing\n",
    ">>2. Price Comparison & Competition Monitoring\n",
    ">>3. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca5dde-4c7e-4d00-8a2f-e27e00db13c2",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a47dd97-77fc-4fa3-95b6-ad2657bd7ff1",
   "metadata": {},
   "source": [
    "### Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb011356-047c-46bd-87a9-7b5557838110",
   "metadata": {},
   "source": [
    "1. HTML Parsing\n",
    "2. DOM Parsing\n",
    "3. Vertical Aggregation\n",
    "4. XPath\n",
    "5. Google Sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79688aa5-a74f-47ac-a203-8f5d0b18a742",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a4e84-1ed8-4a2f-bcf0-7c6feec5e7bf",
   "metadata": {},
   "source": [
    "### Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab225f-98f5-4479-8f6a-6cdde9f4c873",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Beautiful Soup is a Python library designed for quick turnaround projects like screen-scraping.\n",
    "\n",
    "1. Beautiful Soup provides a few simple methods and Pythonic idioms for navigating, searching, and modifying a parse tree: a toolkit for dissecting a document and extracting what you need. It doesn't take much code to write an application.\n",
    "2. Beautiful Soup automatically converts incoming documents to Unicode and outgoing documents to UTF-8. You don't have to think about encodings, unless the document doesn't specify an encoding and Beautiful Soup can't detect one. Then you just have to specify the original encoding.\n",
    "3. Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, allowing you to try out different parsing strategies or trade speed for flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e09011-ede4-46fb-adbe-3afa3d2e9610",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8693e4c-db6c-4e32-bff1-4ee69b0cab71",
   "metadata": {},
   "source": [
    "### Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e76ce57-2933-4ea6-8bba-7aa23a41643d",
   "metadata": {},
   "source": [
    "> Flask is a lightweight python framework to build websites. Weâ€™ll use this to parse our collected data and display it as website through a new HTML file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a90e98-087c-467b-8360-15400c1094c3",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a58c7-c1ff-4ead-9120-6b4fa0ac7280",
   "metadata": {},
   "source": [
    "### Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b42fb05-82df-4e18-a3d8-6eae9623b382",
   "metadata": {},
   "source": [
    "> We use\n",
    "\n",
    "1. aws beanstalk (to deploy flask app)\n",
    ">> search elastic beanstalk > create new environment > select web server environment > create application > application name > select python in environment > create application\n",
    "\n",
    "2. AWS CodePipeline (to connect aws and github).\n",
    ">> create pipeline > name of the pipeline > create >in source ::  slect github version 1 > connect github> login github > select git repository > select branch > next > skip :: build provider >> add deploy stage :: select = aws elastic beanstag > copy appliation name from aws beanstag > select environment name> next review> create pipeline>waituntil complete > copy application name url.\n",
    ">> search the link."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a85cc-da6c-4e7a-89e5-5bae9c840402",
   "metadata": {},
   "source": [
    "______________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
