{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b87dfe0-6c10-42f1-8775-a16717542916",
   "metadata": {},
   "source": [
    "### Q1. What is data encoding? How is it useful in data science?\n",
    "\n",
    "- Data encoding is the process of converting data from one format to another. In data science, this is often done to convert categorical data into numerical data. This is important because machine learning algorithms can only work with numerical data.\n",
    "\n",
    "________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf5b1b-8555-44cf-ac6a-66075c38164f",
   "metadata": {},
   "source": [
    "### Q2. What is nominal encoding? Provide an example of how you would use it in a real-world scenario.\n",
    "\n",
    "- Nominal encoding is a type of data encoding that is used for categorical variables with no inherent order. In other words, the categories in a nominal variable are simply names, and there is no way to rank them in terms of size, importance, or any other criteria.\n",
    "\n",
    "    - One example of a nominal variable is the gender of a person. The categories in this variable are male and female, and there is no way to rank these categories in terms of size, importance, or any other criteria.\n",
    "\n",
    "    - Another example of a nominal variable is the city where a person lives. The categories in this variable are New York City, Los Angeles, Chicago, and so on, and there is no way to rank these cities in terms of size, importance, or any other criteria.\n",
    "\n",
    "    Nominal encoding is a simple way to convert categorical data into numerical data. It is done by assigning a unique number to each category in the categorical variable. \n",
    "    - For example, the gender variable could be encoded as follows:\n",
    "\n",
    "    male = 0\n",
    "    female = 1\n",
    "    \n",
    "    - The city variable could be encoded as follows:\n",
    "\n",
    "    New York City = 0\n",
    "    Los Angeles = 1\n",
    "    Chicago = 2\n",
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9430ba30-55fb-42d0-aaab-38eb47ecbbe8",
   "metadata": {},
   "source": [
    "### Q3. In what situations is nominal encoding preferred over one-hot encoding? Provide a practical example.\n",
    "Nominal encoding is preferred over one-hot encoding in situations where the order of the categories does not matter. For example, if you have a categorical feature called \"color\" with the values \"red\", \"green\", and \"blue\", then nominal encoding would simply assign each value a unique integer label, such as 0 for \"red\", 1 for \"green\", and 2 for \"blue\". This would preserve the information that there are three categories, but it would not impose any order on the categories.\n",
    "\n",
    "One-hot encoding, on the other hand, would create three new binary columns, one for each category. The \"red\" column would be 1 if the value of the \"color\" feature is \"red\", and 0 otherwise. The \"green\" column would be 1 if the value of the \"color\" feature is \"green\", and 0 otherwise, and so on. This would preserve the information that there are three categories, and it would also encode the order of the categories.\n",
    "\n",
    "In some cases, the order of the categories is important. For example, if you are trying to predict the price of a car, and the car's color is one of the features, then the order of the colors might matter. A red car might be more expensive than a green car, and a green car might be more expensive than a blue car. In this case, one-hot encoding would be the better choice.\n",
    "\n",
    "However, in many cases, the order of the categories does not matter. For example, if you are trying to predict whether a customer will click on an ad, and the customer's gender is one of the features, then the order of the genders (male, female) does not matter. In this case, nominal encoding would be the better choice.\n",
    "\n",
    "Here is a Python example of how to perform nominal encoding and one-hot encoding using the scikit-learn library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d3f87a-b28c-4201-b2ab-852f51fc048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sizes: ['small', 'medium', 'large', 'medium', 'extra-large', 'large', 'small']\n",
      "Encoded Sizes (Nominal Encoding): [3 2 1 2 0 1 3]\n",
      "Encoded Sizes (One-Hot Encoding):\n",
      " [[0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Sample data for the \"size\" feature\n",
    "sizes = ['small', 'medium', 'large', 'medium', 'extra-large', 'large', 'small']\n",
    "\n",
    "# Create a LabelEncoder for nominal encoding\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_sizes = label_encoder.fit_transform(sizes)\n",
    "\n",
    "print(\"Original Sizes:\", sizes)\n",
    "print(\"Encoded Sizes (Nominal Encoding):\", encoded_sizes)\n",
    "\n",
    "# Create a OneHotEncoder for one-hot encoding\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "encoded_sizes_one_hot = one_hot_encoder.fit_transform(encoded_sizes.reshape(-1, 1))\n",
    "\n",
    "print(\"Encoded Sizes (One-Hot Encoding):\\n\", encoded_sizes_one_hot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429737f2-3728-475c-bd0c-13364164698f",
   "metadata": {},
   "source": [
    "### Q4. Suppose you have a dataset containing categorical data with 5 unique values. Which encoding technique would you use to transform this data into a format suitable for machine learning algorithms? Explain why you made this choice.\n",
    "\n",
    "If the dataset contains categorical data with 5 unique values, the appropriate encoding technique to transform the data into a format suitable for machine learning algorithms would be one-hot encoding.\n",
    "\n",
    "One-hot encoding is the preferred choice when dealing with categorical variables that have no inherent order or ranking among the categories. It creates binary columns for each category, with a value of 1 indicating the presence of that category and 0 otherwise. One-hot encoding ensures that no artificial ordinal relationship is introduced between the categories, making it suitable for nominal data.\n",
    "\n",
    "In this case, since the dataset contains 5 unique values (categories) and there is no inherent order or ranking among them, one-hot encoding will be the most appropriate encoding technique. Each unique value will be represented by its own binary column, and the machine learning algorithm will be able to handle the categorical data properly without assuming any ordinal relationship between the categories. This approach avoids introducing any bias in the data representation and allows the model to interpret the categorical data correctly.\n",
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83faaf-a727-49ce-865b-b7af0991d462",
   "metadata": {},
   "source": [
    "### Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns are categorical, and the remaining three columns are numerical. If you were to use nominal encoding to transform the categorical data, how many new columns would be created? Show your calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4392746a-9465-4398-89ba-4f3a5861dc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new columns after nominal encoding: 6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data for the dataset\n",
    "data = {\n",
    "    'category1': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A'],\n",
    "    'category2': ['X', 'Y', 'X', 'Y', 'X', 'Z', 'Y', 'X', 'Z', 'X'],\n",
    "    'numerical1': [10, 20, 15, 25, 30, 40, 35, 45, 50, 55],\n",
    "    'numerical2': [5, 8, 10, 12, 15, 20, 18, 22, 25, 28],\n",
    "    'numerical3': [100, 150, 120, 180, 200, 250, 220, 300, 280, 350]\n",
    "}\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Select the categorical columns for nominal encoding\n",
    "categorical_columns = ['category1', 'category2']\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Perform nominal encoding on the categorical columns\n",
    "encoded_columns = df[categorical_columns].apply(label_encoder.fit_transform)\n",
    "\n",
    "# Count the number of unique categories in each column\n",
    "num_new_columns = encoded_columns.nunique().sum()\n",
    "\n",
    "print(\"Number of new columns after nominal encoding:\", num_new_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3fb327-5bf7-425a-abd1-dafc89ce4e4f",
   "metadata": {},
   "source": [
    "### Q6. You are working with a dataset containing information about different types of animals, including their species, habitat, and diet. Which encoding technique would you use to transform the categorical data into a format suitable for machine learning algorithms? Justify your answer.\n",
    "\n",
    "    In the scenario where you are working with a dataset containing information about different types of animals, including their species, habitat, and diet, the appropriate encoding technique to transform the categorical data into a format suitable for machine learning algorithms would be one-hot encoding, not label encoding.\n",
    "\n",
    "Justification:\n",
    "\n",
    "1. Categorical Variables: The dataset contains multiple categorical variables such as species, habitat, and diet. Categorical variables represent distinct categories without any inherent order or ranking. One-hot encoding is best suited for handling such categorical data.\n",
    "\n",
    "2. No Ordinal Relationship: Label encoding, which assigns unique integer values to each category, introduces an artificial ordinal relationship between the categories. In this case, assigning numerical labels to species, habitat, or diet could lead the machine learning model to assume an ordinal relationship between different species, habitats, or diets, which is not appropriate in the context of animal data.\n",
    "\n",
    "3. Avoid Bias: One-hot encoding ensures that no artificial ordinal relationship is introduced between the categories. Each unique category is represented by its own binary column, and the machine learning algorithm will treat each category independently without assuming any order or ranking.\n",
    "\n",
    "4. Interpretability: One-hot encoding provides a more interpretable representation of categorical data. Each category is represented by a binary feature, making it easier to understand the contribution of each category to the model's predictions.\n",
    "\n",
    "Considering the nature of the data with multiple categorical variables representing distinct categories without any inherent order, one-hot encoding is the most suitable encoding technique to ensure that the model interprets the categorical data correctly and avoids any bias introduced by label encoding.\n",
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdbdb9c-56e3-4ea5-b4d6-81bd8f9721c3",
   "metadata": {},
   "source": [
    "### Q7.You are working on a project that involves predicting customer churn for a telecommunications company. You have a dataset with 5 features, including the customer's gender, age, contract type, monthly charges, and tenure. Which encoding technique(s) would you use to transform the categorical data into numerical data? Provide a step-by-step explanation of how you would implement the encoding.\n",
    "\n",
    "To transform the categorical data into numerical data for the customer churn prediction project, we would use one-hot encoding for the \"gender\" and \"contract type\" features. The \"gender\" feature has two categories (e.g., male and female), and the \"contract type\" feature likely has more than two categories (e.g., monthly, yearly, two-year contract). Since both these features are nominal and do not have any inherent order or ranking, one-hot encoding would be the appropriate choice.\n",
    "\n",
    "Step-by-step explanation of implementing one-hot encoding:\n",
    "\n",
    "1. Load the Dataset: Start by loading the dataset containing the customer churn data, which includes features like gender, age, contract type, monthly charges, and tenure.\n",
    "\n",
    "2. Separate Categorical and Numerical Features: Identify the categorical features (\"gender\" and \"contract type\") and the numerical features (\"age,\" \"monthly charges,\" and \"tenure\") in the dataset.\n",
    "\n",
    "3. Perform One-Hot Encoding: Apply one-hot encoding specifically to the \"gender\" and \"contract type\" columns. This will create binary columns for each category, indicating the presence (1) or absence (0) of that category for each customer.\n",
    "\n",
    "\n",
    "\n",
    "In this example, one-hot encoding is applied to the \"gender\" and \"contract type\" features using the `OneHotEncoder` class from sklearn. The resulting DataFrame `processed_data` contains the numerical representations of the categorical features as well as the original numerical features, which can now be used for machine learning model training to predict customer churn.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5336b05-a934-4194-9e70-f22d48634b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  monthly_charges  tenure  gender_male  contract_type_two-year  \\\n",
      "0   30               50       6          1.0                     0.0   \n",
      "1   40               70      12          0.0                     0.0   \n",
      "2   25               60       3          1.0                     0.0   \n",
      "3   35               80      24          0.0                     0.0   \n",
      "4   50               90      18          1.0                     1.0   \n",
      "\n",
      "   contract_type_yearly  \n",
      "0                   0.0  \n",
      "1                   1.0  \n",
      "2                   0.0  \n",
      "3                   1.0  \n",
      "4                   0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Sample data for demonstration purposes\n",
    "data = {\n",
    "    'gender': ['male', 'female', 'male', 'female', 'male'],\n",
    "    'age': [30, 40, 25, 35, 50],\n",
    "    'contract_type': ['monthly', 'yearly', 'monthly', 'yearly', 'two-year'],\n",
    "    'monthly_charges': [50, 70, 60, 80, 90],\n",
    "    'tenure': [6, 12, 3, 24, 18]\n",
    "}\n",
    "\n",
    "# Convert data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separate categorical and numerical features\n",
    "categorical_features = ['gender', 'contract_type']\n",
    "numerical_features = ['age', 'monthly_charges', 'tenure']\n",
    "\n",
    "# Apply one-hot encoding to categorical features\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "encoded_features = encoder.fit_transform(df[categorical_features])\n",
    "\n",
    "# Get the names of the encoded features\n",
    "encoded_feature_names = encoder.get_feature_names_out(input_features=categorical_features)\n",
    "\n",
    "# Create a DataFrame for the encoded features\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoded_feature_names)\n",
    "\n",
    "# Combine the numerical features and the one-hot encoded features\n",
    "processed_data = pd.concat([df[numerical_features], encoded_df], axis=1)\n",
    "\n",
    "print(processed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d4f6a-ce9a-46da-bc7c-3ab0c0e4963a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
